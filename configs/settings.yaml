default:
  Title: watsonx evaluation

development:
  generate_answer:
    llm_generate:
      name: meta-llama/llama-3-8b-instruct
      decoding_method: "greedy"
      max_new_tokens: 300
      min_new_tokens: 30
      repetition_penalty: 1
    embedder_model:
      source: huggingface  # watsonxai huggingface
      name: kornwtp/simcse-model-phayathaibert
      chunk_size: 1200
      overlap_size: 200

  faithfulness:
    llm_divide:
      source: watsonxai
      name: meta-llama/llama-3-8b-instruct
      prompt_language: TH
      decoding_method: "greedy"
      max_new_tokens: 300
      min_new_tokens: 30
      repetition_penalty: 1
      prompt_location: some_location.txt
      

    llm_eval:
      source: watsonxai
      name: meta-llama/llama-3-70b-instruct
      prompt_language: EN
      decoding_method: "greedy"
      max_new_tokens: 300
      min_new_tokens: 30
      repetition_penalty: 1
      prompt_location: 

  answer_relevancy:
    embedder_model: 
      source: watsonxai
      name: ibm/slate-125m-english-rtrvr
      # source: huggingface
      # name: kornwtp/simcse-model-phayathaibert
    llm_predict:
      source: watsonxai
      name: meta-llama/llama-3-70b-instruct
      decoding_method: "greedy"
      max_new_tokens: 300
      min_new_tokens: 30
      repetition_penalty: 1